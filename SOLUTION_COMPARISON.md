# 💡 大数据导入方案对比

## 🎯 你的需求

- **当前**: 20 个期刊 = 1 MB
- **目标**: 15 万个期刊 ≈ **7.5 GB**
- **问题**: 文件太大无法上传

## 🆚 三种方案对比

### ❌ 方案1：单文件上传（当前）

```
用户 → 上传 7.5GB 文件 → 服务器
```

**问题**:
- ❌ 文件太大（7.5 GB）
- ❌ 上传超时
- ❌ 内存爆炸
- ❌ 占用存储空间
- ❌ 不可行

---

### ⚠️ 方案2：分段文件上传

```bash
# 拆分成 150 个文件（每个 1000 个期刊）
ruby split_json.rb journals.json 1000

# 逐个上传
上传 batch_0001.json (50 MB)
上传 batch_0002.json (50 MB)
...
上传 batch_0150.json (50 MB)
```

**优点**:
- ✅ 可以上传

**缺点**:
- ❌ 需要拆分 150 个文件
- ❌ 临时文件占用 7.5 GB 存储
- ❌ 上传后这些文件没用了（浪费）
- ❌ 操作繁琐
- ⏱️ 预计 2-3 小时

---

### ✅ 方案3：REST API 批量导入（推荐）⭐

```python
# 直接从本地 JSON 发送数据，不上传文件
python import_client.py journals_150k.json \
  https://your-domain.com \
  your_api_key \
  admin \
  500 \
  1
```

**工作流程**:
```
本地 JSON → Python 脚本 → 分批读取 → 
→ API POST (每批 500 个) → 
→ 服务器即时处理 → 创建话题 → 
→ 不保存文件
```

**优点**:
- ✅ **不需要上传文件**
- ✅ **不占用服务器存储**（即时处理）
- ✅ **无文件大小限制**（分批发送）
- ✅ **进度可控**（客户端控制）
- ✅ **断点续传**（失败可重试）
- ✅ **编程友好**（易集成）
- ⏱️ **快速**: 15万期刊约 **50 分钟**

**缺点**:
- ⚠️ 需要 Python 环境（但很简单）

---

## 📊 性能对比

| 指标 | 文件上传 | 分段上传 | API 导入 |
|------|---------|---------|---------|
| **15万期刊耗时** | ❌ 无法完成 | ⏱️ 2-3小时 | ✅ 50分钟 |
| **服务器存储占用** | 7.5 GB | 7.5 GB | 0 GB |
| **本地操作** | 上传1个文件 | 上传150个文件 | 运行1个命令 |
| **失败重试** | ❌ 全部重来 | ⚠️ 手动重传 | ✅ 自动继续 |
| **进度监控** | ❌ 无 | ⚠️ 手动 | ✅ 实时显示 |
| **内存占用** | ❌ 7.5 GB | ⚠️ 50 MB/批 | ✅ 10 MB/批 |
| **编程集成** | ❌ 困难 | ❌ 困难 | ✅ 简单 |

---

## 🚀 推荐方案：REST API

### 为什么选择 API？

1. **专业标准**: 业界主流方案（GitHub、AWS、阿里云都这样做）
2. **高效可靠**: 50分钟完成15万期刊
3. **资源节约**: 不浪费7.5GB存储空间
4. **易于使用**: 一行命令搞定
5. **可扩展**: 未来100万期刊也没问题

### 快速开始

#### 1. 部署 API 端点（5分钟）

```bash
cd /Users/youngp/discourse/plugins/discourse-journals
git add .
git commit -m "Add REST API for batch import"
git push

ssh user@server
cd /var/www/discourse/plugins/discourse-journals
git pull
cd /var/www/discourse
sv restart unicorn
```

#### 2. 获取 API Key（2分钟）

访问: `https://your-domain.com/admin/api`
创建新 API Key，保存。

#### 3. 运行导入（50分钟）

```bash
cd /Users/youngp/discourse/plugins/discourse-journals/scripts

# 安装 Python 依赖（如果需要）
pip install requests

# 导入
python import_client.py \
  /path/to/journals_150k.json \
  https://your-domain.com \
  your_api_key \
  admin \
  500 \
  1
```

#### 实时进度显示：

```
📊 总期刊数: 150,000
📦 每批数量: 500
⏱  批次延迟: 1s

[1/300] 导入 500 个期刊...
  ✅ 成功: 490 新建, 8 更新, 2 跳过
  ⏳ 等待 1s...

[2/300] 导入 500 个期刊...
  ✅ 成功: 495 新建, 3 更新, 2 跳过
  ⏳ 等待 1s...

...

[300/300] 导入 500 个期刊...
  ✅ 成功: 485 新建, 12 更新, 3 跳过

==================================================
🎉 导入完成！
✅ 新建: 149,234
🔄 更新: 523
⏭  跳过: 243
```

---

## 💰 成本对比

### 分段上传
- 服务器存储: 7.5 GB × 云存储成本
- 人工操作: 手动上传150次
- 带宽: 上传 7.5 GB
- **总成本**: 高 💸💸💸

### API 导入
- 服务器存储: 0 GB
- 人工操作: 运行1个命令
- 带宽: 传输 ~100 MB 数据（压缩后）
- **总成本**: 极低 💸

---

## 🎯 结论

| 方案 | 评分 | 推荐度 |
|------|------|--------|
| 单文件上传 | ⭐ | ❌ 不可行 |
| 分段文件上传 | ⭐⭐ | ⚠️ 勉强可用 |
| **REST API 导入** | ⭐⭐⭐⭐⭐ | ✅ **强烈推荐** |

---

**立即开始使用 REST API 方案！** 🚀

查看 `API_IMPORT.md` 获取详细使用说明。
